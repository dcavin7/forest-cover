{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Forest Cover Classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO9cO7Wc5axx+FAWvKB7Pbx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcavin7/forest-cover/blob/main/Forest_Cover_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this project is to develop a neural network model to predict forest cover type based on cartographic variables. The data available is listed below (source: Codecademy):\n",
        "\n",
        "* Elevation / quantitative /meters / Elevation in meters\n",
        "* Aspect / quantitative / azimuth / Aspect in degrees azimuth\n",
        "* Slope / quantitative / degrees / Slope in degrees\n",
        "* Horizontal_Distance_To_Hydrology / quantitative / meters / Horz Dist to nearest surface water features\n",
        "* Vertical_Distance_To_Hydrology / quantitative / meters / Vert Dist to nearest surface water features\n",
        "* Horizontal_Distance_To_Roadways / quantitative / meters / Horz Dist to nearest roadway\n",
        "* Hillshade_9am / quantitative / 0 to 255 index / Hillshade index at 9am, summer solstice\n",
        "* Hillshade_Noon / quantitative / 0 to 255 index / Hillshade index at noon, summer solstice\n",
        "* Hillshade_3pm / quantitative / 0 to 255 index / Hillshade index at 3pm, summer solstice\n",
        "* Horizontal_Distance_To_Fire_Points / quantitative / meters / Horz Dist to nearest wildfire ignition points\n",
        "* Wilderness_Area (4 binary columns) / qualitative / 0 (absence) or 1 (presence) / Wilderness area designation\n",
        "* Soil_Type (40 binary columns) / qualitative / 0 (absence) or 1 (presence) / Soil Type designation\n",
        "* Cover_Type (7 types) / integer / 1 to 7 / Forest Cover Type designation"
      ],
      "metadata": {
        "id": "oqBNnRhxW7GN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "25Frj8Hu37yp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "BfRGSIn4zEzG"
      },
      "outputs": [],
      "source": [
        "# Importing necessary packages\n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv(io.BytesIO(uploaded['cover_data.csv']))"
      ],
      "metadata": {
        "id": "_lp0cp9o3nAS",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "c638cfd7-1688-4f81-a938-6504f112c4c9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6c25e92c-75f6-43a6-8390-53deabb81946\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6c25e92c-75f6-43a6-8390-53deabb81946\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cover_data.csv to cover_data (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Covertypes corresponding to numerical labels\n",
        "y_labels = [\"Spruce/Fir\",\n",
        "            \"Lodgepole Pine\",\n",
        "            \"Ponderosa Pine\",\n",
        "            \"Cottonwood/Willow\",\n",
        "            \"Aspen\",\n",
        "            \"Douglas-fir\",\n",
        "            \"Krummholz\"]"
      ],
      "metadata": {
        "id": "fC0SP4SwGB9Q"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data exploration"
      ],
      "metadata": {
        "id": "hAWrVJPIWbHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Column summary statistics\n",
        "print(df.describe())\n",
        "\n",
        "# Output cleared for cleanliness"
      ],
      "metadata": {
        "id": "w25JYKZM6Kdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Column attributes / data types\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eZ-j8fzWqkN",
        "outputId": "b62323d1-625f-40ac-e8b6-57686a18b569"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 581012 entries, 0 to 581011\n",
            "Data columns (total 55 columns):\n",
            " #   Column                              Non-Null Count   Dtype\n",
            "---  ------                              --------------   -----\n",
            " 0   Elevation                           581012 non-null  int64\n",
            " 1   Aspect                              581012 non-null  int64\n",
            " 2   Slope                               581012 non-null  int64\n",
            " 3   Horizontal_Distance_To_Hydrology    581012 non-null  int64\n",
            " 4   Vertical_Distance_To_Hydrology      581012 non-null  int64\n",
            " 5   Horizontal_Distance_To_Roadways     581012 non-null  int64\n",
            " 6   Hillshade_9am                       581012 non-null  int64\n",
            " 7   Hillshade_Noon                      581012 non-null  int64\n",
            " 8   Hillshade_3pm                       581012 non-null  int64\n",
            " 9   Horizontal_Distance_To_Fire_Points  581012 non-null  int64\n",
            " 10  Wilderness_Area1                    581012 non-null  int64\n",
            " 11  Wilderness_Area2                    581012 non-null  int64\n",
            " 12  Wilderness_Area3                    581012 non-null  int64\n",
            " 13  Wilderness_Area4                    581012 non-null  int64\n",
            " 14  Soil_Type1                          581012 non-null  int64\n",
            " 15  Soil_Type2                          581012 non-null  int64\n",
            " 16  Soil_Type3                          581012 non-null  int64\n",
            " 17  Soil_Type4                          581012 non-null  int64\n",
            " 18  Soil_Type5                          581012 non-null  int64\n",
            " 19  Soil_Type6                          581012 non-null  int64\n",
            " 20  Soil_Type7                          581012 non-null  int64\n",
            " 21  Soil_Type8                          581012 non-null  int64\n",
            " 22  Soil_Type9                          581012 non-null  int64\n",
            " 23  Soil_Type10                         581012 non-null  int64\n",
            " 24  Soil_Type11                         581012 non-null  int64\n",
            " 25  Soil_Type12                         581012 non-null  int64\n",
            " 26  Soil_Type13                         581012 non-null  int64\n",
            " 27  Soil_Type14                         581012 non-null  int64\n",
            " 28  Soil_Type15                         581012 non-null  int64\n",
            " 29  Soil_Type16                         581012 non-null  int64\n",
            " 30  Soil_Type17                         581012 non-null  int64\n",
            " 31  Soil_Type18                         581012 non-null  int64\n",
            " 32  Soil_Type19                         581012 non-null  int64\n",
            " 33  Soil_Type20                         581012 non-null  int64\n",
            " 34  Soil_Type21                         581012 non-null  int64\n",
            " 35  Soil_Type22                         581012 non-null  int64\n",
            " 36  Soil_Type23                         581012 non-null  int64\n",
            " 37  Soil_Type24                         581012 non-null  int64\n",
            " 38  Soil_Type25                         581012 non-null  int64\n",
            " 39  Soil_Type26                         581012 non-null  int64\n",
            " 40  Soil_Type27                         581012 non-null  int64\n",
            " 41  Soil_Type28                         581012 non-null  int64\n",
            " 42  Soil_Type29                         581012 non-null  int64\n",
            " 43  Soil_Type30                         581012 non-null  int64\n",
            " 44  Soil_Type31                         581012 non-null  int64\n",
            " 45  Soil_Type32                         581012 non-null  int64\n",
            " 46  Soil_Type33                         581012 non-null  int64\n",
            " 47  Soil_Type34                         581012 non-null  int64\n",
            " 48  Soil_Type35                         581012 non-null  int64\n",
            " 49  Soil_Type36                         581012 non-null  int64\n",
            " 50  Soil_Type37                         581012 non-null  int64\n",
            " 51  Soil_Type38                         581012 non-null  int64\n",
            " 52  Soil_Type39                         581012 non-null  int64\n",
            " 53  Soil_Type40                         581012 non-null  int64\n",
            " 54  class                               581012 non-null  int64\n",
            "dtypes: int64(55)\n",
            "memory usage: 243.8 MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "_xBxl9jEdoI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting features (X) and labels (y)\n",
        "X = df.iloc[:,0:-1] # All columns except last (class)\n",
        "y = df.iloc[:,-1] # Only class column"
      ],
      "metadata": {
        "id": "_lYeEd5nd8Bh"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42, stratify = y)\n",
        "\n",
        "# Undersampling\n",
        "rus = RandomUnderSampler(random_state = 10)\n",
        "# Using undersampling to correct imbalanced dataset (training data only)\n",
        "X_train, y_train = rus.fit_resample(X_train, y_train)\n",
        "\n",
        "# Shuffling\n",
        "# To prevent bias in training\n",
        "xy_train = pd.concat([X_train, y_train], join = 'inner', axis = 1) # Join x and y to shuffle\n",
        "xy_train = xy_train.sample(frac = 1, random_state = 100) # Shuffle\n",
        "# Re-separating the data\n",
        "X_train = xy_train.iloc[:,0:-1] # All columns except last (class)\n",
        "y_train = xy_train.iloc[:,-1] # Only class column"
      ],
      "metadata": {
        "id": "DtU26fQ7eoSg"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Coding y as 0-6 instead of 1-7\n",
        "le = LabelEncoder()\n",
        "\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "\n",
        "y_test = le.transform(y_test)\n",
        "y_test = pd.DataFrame(y_test)"
      ],
      "metadata": {
        "id": "isAgaR68hgD4"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling\n",
        "column_trans = ColumnTransformer(\n",
        "    [('scaler', StandardScaler(), slice(0, 10))],\n",
        "    remainder = 'passthrough')\n",
        "# Only qualitative columns are scaled. Categorical columns are left as-is.\n",
        "\n",
        "X_train_scaled = column_trans.fit_transform(X_train)\n",
        "X_test_scaled = column_trans.transform(X_test)\n",
        "\n",
        "# Converting back to Pandas dataframe\n",
        "X_columns = X.columns\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns = X_columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns = X_columns)"
      ],
      "metadata": {
        "id": "PhQfM0agfOHn"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the Model"
      ],
      "metadata": {
        "id": "8-5FHHscvp9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Input\n",
        "model.add(tf.keras.Input(shape = (X_train_scaled.shape[1], )))\n",
        "\n",
        "# Hidden layer 1\n",
        "model.add(tf.keras.layers.Dense(64, activation = 'relu'))\n",
        "\n",
        "# Hidden layer 2\n",
        "model.add(tf.keras.layers.Dense(32, activation = 'relu'))\n",
        "\n",
        "# Hidden layer 3\n",
        "model.add(tf.keras.layers.Dense(16, activation = 'relu'))\n",
        "\n",
        "# Output\n",
        "model.add(tf.keras.layers.Dense(7, activation = 'softmax'))"
      ],
      "metadata": {
        "id": "RAghtoT4vsYc"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = 0.0005)"
      ],
      "metadata": {
        "id": "9Lls5to8IsEQ"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling model\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', \n",
        "              optimizer = opt,\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "3y4BShGHx-VX"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting model\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\n",
        "                                              mode = 'max',\n",
        "                                              patience = 20,\n",
        "                                              restore_best_weights = True)\n",
        "model.fit(X_train_scaled, y_train,\n",
        "          epochs = 100,\n",
        "          batch_size = 5,\n",
        "          verbose = 1,\n",
        "          validation_split = 0.2,\n",
        "          shuffle = True,\n",
        "          callbacks = [early_stop]\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sejg-i2C_xFJ",
        "outputId": "c44a0964-a323-42a9-b3af-b6e4d97940ab"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.9806 - accuracy: 0.5958 - val_loss: 0.7220 - val_accuracy: 0.7073\n",
            "Epoch 2/100\n",
            "2769/2769 [==============================] - 6s 2ms/step - loss: 0.6687 - accuracy: 0.7195 - val_loss: 0.6629 - val_accuracy: 0.7244\n",
            "Epoch 3/100\n",
            "2769/2769 [==============================] - 6s 2ms/step - loss: 0.6213 - accuracy: 0.7384 - val_loss: 0.6196 - val_accuracy: 0.7382\n",
            "Epoch 4/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.5899 - accuracy: 0.7511 - val_loss: 0.6000 - val_accuracy: 0.7475\n",
            "Epoch 5/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.5656 - accuracy: 0.7631 - val_loss: 0.5860 - val_accuracy: 0.7564\n",
            "Epoch 6/100\n",
            "2769/2769 [==============================] - 6s 2ms/step - loss: 0.5459 - accuracy: 0.7701 - val_loss: 0.5834 - val_accuracy: 0.7556\n",
            "Epoch 7/100\n",
            "2769/2769 [==============================] - 8s 3ms/step - loss: 0.5297 - accuracy: 0.7802 - val_loss: 0.5545 - val_accuracy: 0.7732\n",
            "Epoch 8/100\n",
            "2769/2769 [==============================] - 6s 2ms/step - loss: 0.5166 - accuracy: 0.7841 - val_loss: 0.5675 - val_accuracy: 0.7654\n",
            "Epoch 9/100\n",
            "2769/2769 [==============================] - 6s 2ms/step - loss: 0.5045 - accuracy: 0.7899 - val_loss: 0.5540 - val_accuracy: 0.7732\n",
            "Epoch 10/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.4936 - accuracy: 0.7946 - val_loss: 0.5603 - val_accuracy: 0.7680\n",
            "Epoch 11/100\n",
            "2769/2769 [==============================] - 6s 2ms/step - loss: 0.4845 - accuracy: 0.8003 - val_loss: 0.5422 - val_accuracy: 0.7813\n",
            "Epoch 12/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.4749 - accuracy: 0.8031 - val_loss: 0.5367 - val_accuracy: 0.7836\n",
            "Epoch 13/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.4651 - accuracy: 0.8068 - val_loss: 0.5281 - val_accuracy: 0.7856\n",
            "Epoch 14/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.4562 - accuracy: 0.8114 - val_loss: 0.5241 - val_accuracy: 0.7943\n",
            "Epoch 15/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.4510 - accuracy: 0.8155 - val_loss: 0.5297 - val_accuracy: 0.7888\n",
            "Epoch 16/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.4416 - accuracy: 0.8207 - val_loss: 0.5201 - val_accuracy: 0.7966\n",
            "Epoch 17/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.4357 - accuracy: 0.8193 - val_loss: 0.5160 - val_accuracy: 0.8041\n",
            "Epoch 18/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.4282 - accuracy: 0.8240 - val_loss: 0.5139 - val_accuracy: 0.8015\n",
            "Epoch 19/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.4230 - accuracy: 0.8264 - val_loss: 0.4988 - val_accuracy: 0.8018\n",
            "Epoch 20/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.4148 - accuracy: 0.8283 - val_loss: 0.5127 - val_accuracy: 0.8032\n",
            "Epoch 21/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.4085 - accuracy: 0.8331 - val_loss: 0.5226 - val_accuracy: 0.7963\n",
            "Epoch 22/100\n",
            "2769/2769 [==============================] - 6s 2ms/step - loss: 0.4037 - accuracy: 0.8374 - val_loss: 0.5138 - val_accuracy: 0.7998\n",
            "Epoch 23/100\n",
            "2769/2769 [==============================] - 8s 3ms/step - loss: 0.3991 - accuracy: 0.8369 - val_loss: 0.5140 - val_accuracy: 0.8050\n",
            "Epoch 24/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.3933 - accuracy: 0.8405 - val_loss: 0.5042 - val_accuracy: 0.8024\n",
            "Epoch 25/100\n",
            "2769/2769 [==============================] - 6s 2ms/step - loss: 0.3930 - accuracy: 0.8397 - val_loss: 0.4951 - val_accuracy: 0.8133\n",
            "Epoch 26/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.3843 - accuracy: 0.8453 - val_loss: 0.5069 - val_accuracy: 0.8035\n",
            "Epoch 27/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.3804 - accuracy: 0.8446 - val_loss: 0.5259 - val_accuracy: 0.8001\n",
            "Epoch 28/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.3741 - accuracy: 0.8468 - val_loss: 0.5195 - val_accuracy: 0.8006\n",
            "Epoch 29/100\n",
            "2769/2769 [==============================] - 6s 2ms/step - loss: 0.3730 - accuracy: 0.8499 - val_loss: 0.5103 - val_accuracy: 0.8102\n",
            "Epoch 30/100\n",
            "2769/2769 [==============================] - 6s 2ms/step - loss: 0.3679 - accuracy: 0.8510 - val_loss: 0.5005 - val_accuracy: 0.8142\n",
            "Epoch 31/100\n",
            "2769/2769 [==============================] - 6s 2ms/step - loss: 0.3657 - accuracy: 0.8521 - val_loss: 0.4919 - val_accuracy: 0.8157\n",
            "Epoch 32/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.3612 - accuracy: 0.8544 - val_loss: 0.4934 - val_accuracy: 0.8142\n",
            "Epoch 33/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.3573 - accuracy: 0.8542 - val_loss: 0.5054 - val_accuracy: 0.8105\n",
            "Epoch 34/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.3534 - accuracy: 0.8549 - val_loss: 0.4960 - val_accuracy: 0.8177\n",
            "Epoch 35/100\n",
            "2769/2769 [==============================] - 6s 2ms/step - loss: 0.3511 - accuracy: 0.8574 - val_loss: 0.4955 - val_accuracy: 0.8151\n",
            "Epoch 36/100\n",
            "2769/2769 [==============================] - 6s 2ms/step - loss: 0.3458 - accuracy: 0.8606 - val_loss: 0.5020 - val_accuracy: 0.8203\n",
            "Epoch 37/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.3421 - accuracy: 0.8595 - val_loss: 0.5022 - val_accuracy: 0.8107\n",
            "Epoch 38/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.3443 - accuracy: 0.8603 - val_loss: 0.5191 - val_accuracy: 0.8076\n",
            "Epoch 39/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.3396 - accuracy: 0.8652 - val_loss: 0.5022 - val_accuracy: 0.8139\n",
            "Epoch 40/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.3355 - accuracy: 0.8655 - val_loss: 0.5038 - val_accuracy: 0.8136\n",
            "Epoch 41/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.3332 - accuracy: 0.8628 - val_loss: 0.5037 - val_accuracy: 0.8157\n",
            "Epoch 42/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.3302 - accuracy: 0.8656 - val_loss: 0.4847 - val_accuracy: 0.8252\n",
            "Epoch 43/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.3295 - accuracy: 0.8679 - val_loss: 0.4801 - val_accuracy: 0.8275\n",
            "Epoch 44/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.3237 - accuracy: 0.8692 - val_loss: 0.4895 - val_accuracy: 0.8249\n",
            "Epoch 45/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.3201 - accuracy: 0.8706 - val_loss: 0.5163 - val_accuracy: 0.8148\n",
            "Epoch 46/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.3212 - accuracy: 0.8685 - val_loss: 0.5133 - val_accuracy: 0.8133\n",
            "Epoch 47/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.3166 - accuracy: 0.8693 - val_loss: 0.4866 - val_accuracy: 0.8223\n",
            "Epoch 48/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.3145 - accuracy: 0.8742 - val_loss: 0.4960 - val_accuracy: 0.8252\n",
            "Epoch 49/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.3101 - accuracy: 0.8763 - val_loss: 0.5045 - val_accuracy: 0.8174\n",
            "Epoch 50/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.3106 - accuracy: 0.8744 - val_loss: 0.5060 - val_accuracy: 0.8223\n",
            "Epoch 51/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.3070 - accuracy: 0.8765 - val_loss: 0.4915 - val_accuracy: 0.8249\n",
            "Epoch 52/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.3071 - accuracy: 0.8765 - val_loss: 0.5099 - val_accuracy: 0.8200\n",
            "Epoch 53/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.3046 - accuracy: 0.8757 - val_loss: 0.4983 - val_accuracy: 0.8318\n",
            "Epoch 54/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.3013 - accuracy: 0.8783 - val_loss: 0.4847 - val_accuracy: 0.8324\n",
            "Epoch 55/100\n",
            "2769/2769 [==============================] - 8s 3ms/step - loss: 0.2979 - accuracy: 0.8808 - val_loss: 0.5116 - val_accuracy: 0.8200\n",
            "Epoch 56/100\n",
            "2769/2769 [==============================] - 6s 2ms/step - loss: 0.2975 - accuracy: 0.8799 - val_loss: 0.5214 - val_accuracy: 0.8162\n",
            "Epoch 57/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.2955 - accuracy: 0.8822 - val_loss: 0.4991 - val_accuracy: 0.8292\n",
            "Epoch 58/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2921 - accuracy: 0.8841 - val_loss: 0.5123 - val_accuracy: 0.8243\n",
            "Epoch 59/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2884 - accuracy: 0.8818 - val_loss: 0.5084 - val_accuracy: 0.8243\n",
            "Epoch 60/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.2863 - accuracy: 0.8842 - val_loss: 0.5270 - val_accuracy: 0.8232\n",
            "Epoch 61/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2848 - accuracy: 0.8863 - val_loss: 0.5113 - val_accuracy: 0.8258\n",
            "Epoch 62/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.2863 - accuracy: 0.8849 - val_loss: 0.5076 - val_accuracy: 0.8229\n",
            "Epoch 63/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.2811 - accuracy: 0.8885 - val_loss: 0.5087 - val_accuracy: 0.8298\n",
            "Epoch 64/100\n",
            "2769/2769 [==============================] - 6s 2ms/step - loss: 0.2809 - accuracy: 0.8869 - val_loss: 0.5306 - val_accuracy: 0.8197\n",
            "Epoch 65/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.2766 - accuracy: 0.8864 - val_loss: 0.5147 - val_accuracy: 0.8298\n",
            "Epoch 66/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2741 - accuracy: 0.8873 - val_loss: 0.4964 - val_accuracy: 0.8316\n",
            "Epoch 67/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.2753 - accuracy: 0.8885 - val_loss: 0.5157 - val_accuracy: 0.8258\n",
            "Epoch 68/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2719 - accuracy: 0.8925 - val_loss: 0.5181 - val_accuracy: 0.8281\n",
            "Epoch 69/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2705 - accuracy: 0.8897 - val_loss: 0.5219 - val_accuracy: 0.8316\n",
            "Epoch 70/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2680 - accuracy: 0.8914 - val_loss: 0.5335 - val_accuracy: 0.8255\n",
            "Epoch 71/100\n",
            "2769/2769 [==============================] - 8s 3ms/step - loss: 0.2697 - accuracy: 0.8938 - val_loss: 0.5124 - val_accuracy: 0.8278\n",
            "Epoch 72/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.2672 - accuracy: 0.8920 - val_loss: 0.4998 - val_accuracy: 0.8333\n",
            "Epoch 73/100\n",
            "2769/2769 [==============================] - 6s 2ms/step - loss: 0.2660 - accuracy: 0.8904 - val_loss: 0.5126 - val_accuracy: 0.8287\n",
            "Epoch 74/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.2638 - accuracy: 0.8953 - val_loss: 0.5452 - val_accuracy: 0.8238\n",
            "Epoch 75/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2623 - accuracy: 0.8928 - val_loss: 0.5190 - val_accuracy: 0.8255\n",
            "Epoch 76/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.2576 - accuracy: 0.8956 - val_loss: 0.5474 - val_accuracy: 0.8258\n",
            "Epoch 77/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2590 - accuracy: 0.8963 - val_loss: 0.5267 - val_accuracy: 0.8261\n",
            "Epoch 78/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2574 - accuracy: 0.8976 - val_loss: 0.5257 - val_accuracy: 0.8321\n",
            "Epoch 79/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.2558 - accuracy: 0.8943 - val_loss: 0.5479 - val_accuracy: 0.8226\n",
            "Epoch 80/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.2540 - accuracy: 0.8953 - val_loss: 0.5480 - val_accuracy: 0.8310\n",
            "Epoch 81/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2528 - accuracy: 0.8996 - val_loss: 0.5421 - val_accuracy: 0.8223\n",
            "Epoch 82/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2520 - accuracy: 0.8971 - val_loss: 0.5679 - val_accuracy: 0.8229\n",
            "Epoch 83/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.2500 - accuracy: 0.8999 - val_loss: 0.5410 - val_accuracy: 0.8292\n",
            "Epoch 84/100\n",
            "2769/2769 [==============================] - 6s 2ms/step - loss: 0.2454 - accuracy: 0.9033 - val_loss: 0.5768 - val_accuracy: 0.8142\n",
            "Epoch 85/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.2480 - accuracy: 0.9005 - val_loss: 0.5476 - val_accuracy: 0.8330\n",
            "Epoch 86/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.2447 - accuracy: 0.9029 - val_loss: 0.5458 - val_accuracy: 0.8310\n",
            "Epoch 87/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.2418 - accuracy: 0.9018 - val_loss: 0.5529 - val_accuracy: 0.8269\n",
            "Epoch 88/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2438 - accuracy: 0.9006 - val_loss: 0.5479 - val_accuracy: 0.8336\n",
            "Epoch 89/100\n",
            "2769/2769 [==============================] - 6s 2ms/step - loss: 0.2416 - accuracy: 0.9034 - val_loss: 0.5524 - val_accuracy: 0.8307\n",
            "Epoch 90/100\n",
            "2769/2769 [==============================] - 6s 2ms/step - loss: 0.2403 - accuracy: 0.9040 - val_loss: 0.5347 - val_accuracy: 0.8327\n",
            "Epoch 91/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2379 - accuracy: 0.9022 - val_loss: 0.5433 - val_accuracy: 0.8347\n",
            "Epoch 92/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.2384 - accuracy: 0.9053 - val_loss: 0.5456 - val_accuracy: 0.8350\n",
            "Epoch 93/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2383 - accuracy: 0.9053 - val_loss: 0.5420 - val_accuracy: 0.8327\n",
            "Epoch 94/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.2337 - accuracy: 0.9065 - val_loss: 0.5456 - val_accuracy: 0.8321\n",
            "Epoch 95/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2335 - accuracy: 0.9065 - val_loss: 0.5757 - val_accuracy: 0.8217\n",
            "Epoch 96/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2338 - accuracy: 0.9072 - val_loss: 0.5553 - val_accuracy: 0.8226\n",
            "Epoch 97/100\n",
            "2769/2769 [==============================] - 7s 3ms/step - loss: 0.2330 - accuracy: 0.9067 - val_loss: 0.6030 - val_accuracy: 0.8151\n",
            "Epoch 98/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2326 - accuracy: 0.9061 - val_loss: 0.5587 - val_accuracy: 0.8261\n",
            "Epoch 99/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2309 - accuracy: 0.9085 - val_loss: 0.5720 - val_accuracy: 0.8313\n",
            "Epoch 100/100\n",
            "2769/2769 [==============================] - 7s 2ms/step - loss: 0.2262 - accuracy: 0.9114 - val_loss: 0.5759 - val_accuracy: 0.8310\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2b0b6ff8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scoring the model\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "y_pred = np.argmax(y_pred, axis = 1)\n",
        "#y_true = np.argmax(y_test, axis = 0)\n",
        "print(classification_report(y_test, y_pred, target_names = y_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGz7GF5IJCMt",
        "outputId": "42bd60b3-daf5-4ddb-f3be-9f7020f334ab"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "       Spruce/Fir       0.79      0.68      0.73     21184\n",
            "   Lodgepole Pine       0.80      0.73      0.76     28331\n",
            "   Ponderosa Pine       0.75      0.76      0.75      3575\n",
            "Cottonwood/Willow       0.43      0.99      0.60       275\n",
            "            Aspen       0.26      0.92      0.40       949\n",
            "      Douglas-fir       0.46      0.80      0.59      1737\n",
            "        Krummholz       0.57      0.95      0.71      2051\n",
            "\n",
            "         accuracy                           0.72     58102\n",
            "        macro avg       0.58      0.83      0.65     58102\n",
            "     weighted avg       0.76      0.72      0.73     58102\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_df = pd.DataFrame(y_pred)\n",
        "print(y_pred_df.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eGUvkzf972g",
        "outputId": "ec5fd991-2c09-41c1-f88b-c48af71a59b3"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    25797\n",
            "0    18189\n",
            "2     3648\n",
            "6     3435\n",
            "4     3409\n",
            "5     2986\n",
            "3      638\n",
            "dtype: int64\n"
          ]
        }
      ]
    }
  ]
}